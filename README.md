# NanoGPTExperiment
My attempt at building a generative pretrained transformer ML model, like Chat GPT.
My goal is to build the model piece by piece to gain further understanding of transformers, train it on a small data set of text and then try to generate meaningful output.
![](image.png)
The model was based on the Attention Is All You Need paper (https://arxiv.org/abs/1706.03762), and Andrej Karparthy's amazing tutorials on youtube: https://www.youtube.com/@AndrejKarpathy
